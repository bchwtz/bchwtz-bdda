# Hypothesentests

```{r, echo = F, out.width="80%", fig.cap="[Download Slides](slides/11-Hypothesentests.pdf)"}
knitr::include_graphics("slides/gifs/11-Hypothesentests.gif")
```

## Korrelationskoeffizient (Pearson)

### Theoretische Grundlagen

Der empirische Korrelationskoeffizient nach Pearson $r_{xy}$ als Schätzer für den Korrelationskoeffizienten in der Grundgesamtheit $\rho_{xy}$ ist wie folgt definiert.

$$
r_{xy} = \frac{s_{xy}}{\sqrt{s_x^2 s_y^2}}
$$

Dabei bezeichnet $s_x^2$ die empirische Varianz der Variable $X$, $s_y^2$ die empirische Varianz der Variable $Y$ und $s_{xy}$ die empirische Kovarianz zwischen den Variablen $X$ und $Y$. Die nachfolgende Tabelle zeigt die Hypothesen und die Testvorschriften für einen rechtssseitigen, linksseitigen und beidseitigen Hypothesentest. Die Nullhypothese $H_0: \rho = 0$ entspricht der Annahme der stochastischen Unabhängigkeit. Zur Vereinfachung der Notation wird der Korrelationskoeffizient zwischen $X$ und $Y$, in der nachfolgenden Tabelle nur mit $\rho$ bzw. $r$ bezeichnet.

**Annahmen:** Bivariate Normalverteilung von $X$ und $Y$ in der Grundgesamtheit, $n\leq 30$.

| Hypothesen                             | Testvorschrift: Verwerfe $H_0$, wenn gilt:                                                                              |
|:--------------------------------|:--------------------------------------|
| $H_0: \rho = 0$ vs. $H_1: \rho > 0$    | $\frac{r\sqrt{n-2}}{\sqrt{1-r^2}} > t_{n-2,1-\alpha}$                                                                   |
| $H_0: \rho = 0$ vs. $H_1: \rho < 0$    | $\frac{r\sqrt{n-2}}{\sqrt{1-r^2}} < -t_{n-2,1-\alpha}$                                                                  |
| $H_0: \rho = 0$ vs. $H_1: \rho \neq 0$ | $\frac{r\sqrt{n-2}}{\sqrt{1-r^2}} > t_{n-2,1-\alpha}$ oder $\frac{r\sqrt{n-2}}{\sqrt{1-r^2}} < -t_{n-2,1-\alpha}$ |

### Praktische Anwendung

Angewendet werden kann der Signifikanztest für den Korrelationskoeffizienten nach Pearson in R mit der Funktion `cor.test` unter setzen des Arguments `method = "pearson"`. Die Festlegung der Richtung des Tests (rechtsseitig, linksseitig, beidseitig) durch Spezifikation der Alternativhypothese $H_1$ erlaubt das Argument `alternative`. 

```{r}
x <- c(44.4, 45.9, 41.9, 53.3, 44.7, 44.1, 50.7, 45.2, 60.1)
y <- c( 2.6,  3.1,  2.5,  5.0,  3.6,  4.0,  5.2,  2.8,  3.8)

result <- cor.test(x, y, method = "pearson", alternative = "two.sided")
result
```

Im gezeigten Beispiel wird ein **beidseitiger** Hypothesentest (`alternative = "two.sided"`) für einen fiktiven Datensatz mit $n=$ `r length(x)` Beobachtungen durchgeführt. Der berechnete empirische Korrelationskoeffizient beträgt hier $r_{xy}=$ `r result$estimate`. Die berechnete Teststatistik aus einer $t$-Verteilung mit `r result$parameter` Freiheitsgerade beträgt `r result$statistic`. Die Nullhypothese kann erstmals ab einem Signifikanzniveau von $\alpha^*=$ `r result$p.value` verworfen werden. Angenommen der Test wird mit einem Signifikanzniveau von $\alpha = 0.05 = 5\%$ durchgeführt, so kann die Nullhypothese $H_0$ nicht verworfen werden. Es liegt keine empirische Evidenz für die Abhängigkeit von $X$ und $Y$ in der Grundgesamtheit vor. Es gilt $\rho_{xy}=0$, die Variablen $X$ und $Y$ sind voneinander nicht linear abhängig.

### Ergänzende Erläuterungen

Nachfolgend wird die manuelle Berechnung für die wesentlichen Werte des Hypothesentests nachvollzogen. Die gezeigten Werte sind Deckungsgleich mit den Werten der Funktion `cor.test` aus dem zuvor gezeigten Beispiel.

```{r, eval = FALSE}
# Stichprobengröße auslesen
n <- length(x) <- length(y)

# Teststatistik berechnen
r <- cor(x,y)
teststat <- (r*sqrt(n-2))/sqrt(1-r^2)

# Implizite Irrtumswahrscheinlichkeit berechnen
alpha_imp <- 2 * pt(teststat, df = n-2, lower.tail = FALSE)
```

Um die gezeigte Testvorschrift **manuell** prüfen zu können, wird nach Festlegen der maximalen Irrtumswahrscheinlichkeit $\alpha$ noch der Vergleichswert der $t$-Verteilung (rechte Seite der Ungleichungen aus der Tabelle mit den Testvorschriften) benötigt. Die Funktion `qt` gibt hier die Quantile der $t$-Verteilung an und übernimmt somit die Aufgabe der Verteilungstabelle. Die Testvorschrift kann also auch hier direkt über die oben gezeigten Ungleichungen als auch über das implizite Signifikanzniveau, dem p-Value $\alpha^*$, geprüft werden. Beide Vorgehensweisen führen (natürlich) zu einem identischen Ergebnis.

```{r, eval = FALSE}
# Vergleichsgröße der t-Verteilung bestimmen
alpha <- 0.05
tval <- qt(1-alpha/2, df = n-2)

# Testentscheidung: H0 verwerfen?
# Prüfung mittels Testvorschrift
(teststat > tval) | (teststat < -tval)

# Testentscheidung: H0 verwerfen?
# Prüfung mittels implizitem Signifikanzniveau 
alpha_imp < alpha
```
